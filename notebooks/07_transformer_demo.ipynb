{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07: 完全なTransformerモデル\n",
    "\n",
    "このノートブックでは、EncoderとDecoderを統合した**完全なTransformerモデル**を学習します。\n",
    "\n",
    "## 目次\n",
    "1. Transformerの全体構造\n",
    "2. モデルの作成と順伝播\n",
    "3. シーケンス生成（推論）\n",
    "4. パラメータ数の分析\n",
    "5. 簡単な学習タスク（コピータスク）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('..')\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\n# 日本語フォントの設定（macOS）\nimport matplotlib\nmatplotlib.rcParams['font.family'] = 'Hiragino Sans'\nmatplotlib.rcParams['axes.unicode_minus'] = False  # マイナス記号の文字化け対策\n\nimport numpy as np\n\nfrom src.transformer import Transformer, count_parameters\n\n# デバイスの設定\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelif torch.backends.mps.is_available():\n    device = torch.device('mps')\nelse:\n    device = torch.device('cpu')\nprint(f\"Using device: {device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transformerの全体構造\n",
    "\n",
    "```\n",
    "              ソース入力              ターゲット入力\n",
    "             (日本語文)               (英語文)\n",
    "                 ↓                       ↓\n",
    "         ┌─────────────┐          ┌─────────────┐\n",
    "         │ Embedding   │          │ Embedding   │\n",
    "         └──────┬──────┘          └──────┬──────┘\n",
    "                ↓                        ↓\n",
    "         ┌─────────────┐          ┌─────────────┐\n",
    "         │ + Position  │          │ + Position  │\n",
    "         │  Encoding   │          │  Encoding   │\n",
    "         └──────┬──────┘          └──────┬──────┘\n",
    "                ↓                        ↓\n",
    "        ┌───────────────┐        ┌───────────────┐\n",
    "        │               │        │ Masked Self- │\n",
    "        │  Self-Attn    │        │  Attention   │\n",
    "        │               │        │              │\n",
    "        ├───────────────┤        ├──────────────┤\n",
    "        │  Add & Norm   │        │ Add & Norm   │\n",
    "        ├───────────────┤        ├──────────────┤\n",
    "        │               │   K,V  │              │\n",
    "        │     FFN       │───────→│ Cross-Attn   │\n",
    "        │               │        │              │\n",
    "        ├───────────────┤        ├──────────────┤\n",
    "        │  Add & Norm   │        │ Add & Norm   │\n",
    "        └───────┬───────┘        ├──────────────┤\n",
    "                ↓                │     FFN      │\n",
    "                ↓                ├──────────────┤\n",
    "           × N layers            │ Add & Norm   │\n",
    "                                 └──────┬───────┘\n",
    "                                        ↓\n",
    "                                   × N layers\n",
    "                                        ↓\n",
    "                                 ┌─────────────┐\n",
    "                                 │   Linear    │\n",
    "                                 │  (vocab)    │\n",
    "                                 └──────┬──────┘\n",
    "                                        ↓\n",
    "                                 ┌─────────────┐\n",
    "                                 │   Softmax   │\n",
    "                                 └──────┬──────┘\n",
    "                                        ↓\n",
    "                                    出力確率\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. モデルの作成と順伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ設定\n",
    "src_vocab_size = 1000  # ソース語彙サイズ\n",
    "tgt_vocab_size = 1000  # ターゲット語彙サイズ\n",
    "d_model = 256          # モデル次元\n",
    "num_heads = 8          # Attentionヘッド数\n",
    "num_layers = 4         # Encoder/Decoder層数\n",
    "d_ff = 1024            # FFN中間層次元\n",
    "\n",
    "# モデルの作成\n",
    "model = Transformer(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_encoder_layers=num_layers,\n",
    "    num_decoder_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Total parameters: {count_parameters(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダミー入力で順伝播\n",
    "batch_size = 2\n",
    "src_len = 10\n",
    "tgt_len = 8\n",
    "\n",
    "# ランダムなトークンID（0はパディング、1以上が実際のトークン）\n",
    "src = torch.randint(1, src_vocab_size, (batch_size, src_len)).to(device)\n",
    "tgt = torch.randint(1, tgt_vocab_size, (batch_size, tgt_len)).to(device)\n",
    "\n",
    "print(f\"Source shape: {src.shape}\")\n",
    "print(f\"Target shape: {tgt.shape}\")\n",
    "\n",
    "# 順伝播\n",
    "model.train()\n",
    "logits = model(src, tgt)\n",
    "\n",
    "print(f\"\\nOutput logits shape: {logits.shape}\")\n",
    "print(f\"  - batch_size: {logits.shape[0]}\")\n",
    "print(f\"  - tgt_len: {logits.shape[1]}\")\n",
    "print(f\"  - vocab_size: {logits.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確率分布に変換\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# 最初のバッチ、最初の位置の確率分布を可視化\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(50), probs[0, 0, :50].detach().cpu().numpy())\n",
    "plt.xlabel('Token ID')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Output probability distribution (first 50 tokens)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Most likely token: {probs[0, 0].argmax().item()}\")\n",
    "print(f\"Top-5 tokens: {probs[0, 0].topk(5).indices.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. シーケンス生成（推論）\n",
    "\n",
    "学習済みモデルを使って、ソースから新しいシーケンスを生成します。\n",
    "\n",
    "### 生成方法\n",
    "1. **Greedy（貪欲法）**: 各位置で最も確率の高いトークンを選択\n",
    "2. **サンプリング**: 確率分布からランダムにサンプリング\n",
    "3. **Top-K**: 上位K個のトークンからサンプリング\n",
    "4. **Top-P (Nucleus)**: 累積確率がP以下のトークンからサンプリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy生成\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_greedy = model.greedy_decode(\n",
    "        src, \n",
    "        max_len=15,\n",
    "        start_token_id=1,  # <start>\n",
    "        end_token_id=2,    # <end>\n",
    "    )\n",
    "\n",
    "print(\"Greedy generation:\")\n",
    "print(f\"  Shape: {generated_greedy.shape}\")\n",
    "print(f\"  Batch 0: {generated_greedy[0].tolist()}\")\n",
    "print(f\"  Batch 1: {generated_greedy[1].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプリング生成（温度付き）\n",
    "with torch.no_grad():\n",
    "    # 温度 0.5（より確定的）\n",
    "    generated_temp05 = model.generate(\n",
    "        src,\n",
    "        max_len=15,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    \n",
    "    # 温度 1.5（よりランダム）\n",
    "    generated_temp15 = model.generate(\n",
    "        src,\n",
    "        max_len=15,\n",
    "        temperature=1.5,\n",
    "    )\n",
    "\n",
    "print(\"Temperature 0.5 (more deterministic):\")\n",
    "print(f\"  Batch 0: {generated_temp05[0].tolist()}\")\n",
    "\n",
    "print(\"\\nTemperature 1.5 (more random):\")\n",
    "print(f\"  Batch 0: {generated_temp15[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-K サンプリング\n",
    "with torch.no_grad():\n",
    "    generated_topk = model.generate(\n",
    "        src,\n",
    "        max_len=15,\n",
    "        top_k=10,\n",
    "    )\n",
    "\n",
    "print(\"Top-K (K=10) sampling:\")\n",
    "print(f\"  Batch 0: {generated_topk[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. パラメータ数の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各コンポーネントのパラメータ数を計算\n",
    "def get_param_breakdown(model):\n",
    "    breakdown = {\n",
    "        'Source Embedding': 0,\n",
    "        'Target Embedding': 0,\n",
    "        'Position Encoding': 0,\n",
    "        'Encoder': 0,\n",
    "        'Decoder': 0,\n",
    "        'Output Projection': 0,\n",
    "    }\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'src_embedding' in name:\n",
    "            breakdown['Source Embedding'] += param.numel()\n",
    "        elif 'tgt_embedding' in name:\n",
    "            breakdown['Target Embedding'] += param.numel()\n",
    "        elif 'pos_encoding' in name:\n",
    "            breakdown['Position Encoding'] += param.numel()\n",
    "        elif 'encoder' in name:\n",
    "            breakdown['Encoder'] += param.numel()\n",
    "        elif 'decoder' in name:\n",
    "            breakdown['Decoder'] += param.numel()\n",
    "        elif 'output_projection' in name:\n",
    "            breakdown['Output Projection'] += param.numel()\n",
    "    \n",
    "    return breakdown\n",
    "\n",
    "breakdown = get_param_breakdown(model)\n",
    "total = sum(breakdown.values())\n",
    "\n",
    "print(\"Parameter Breakdown:\")\n",
    "print(\"=\" * 50)\n",
    "for name, count in breakdown.items():\n",
    "    pct = 100 * count / total if total > 0 else 0\n",
    "    print(f\"{name:20s}: {count:>10,} ({pct:5.1f}%)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Total':20s}: {total:>10,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイチャートで可視化\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# 0のエントリを除外\n",
    "labels = [k for k, v in breakdown.items() if v > 0]\n",
    "sizes = [v for v in breakdown.values() if v > 0]\n",
    "\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(labels)))\n",
    "explode = [0.02] * len(labels)\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    sizes, \n",
    "    labels=labels, \n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    explode=explode,\n",
    "    startangle=90,\n",
    ")\n",
    "\n",
    "ax.set_title(f'Transformer Parameter Distribution\\nTotal: {total:,} parameters')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 論文オリジナル設定との比較\n",
    "print(\"Comparison with different model sizes:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "configs = [\n",
    "    (\"Current (small)\", 256, 4, 1024, 1000),\n",
    "    (\"Transformer-Base\", 512, 6, 2048, 32000),\n",
    "    (\"Transformer-Big\", 1024, 6, 4096, 32000),\n",
    "]\n",
    "\n",
    "for name, d, layers, ff, vocab in configs:\n",
    "    temp_model = Transformer(\n",
    "        src_vocab_size=vocab,\n",
    "        tgt_vocab_size=vocab,\n",
    "        d_model=d,\n",
    "        num_heads=8,\n",
    "        num_encoder_layers=layers,\n",
    "        num_decoder_layers=layers,\n",
    "        d_ff=ff,\n",
    "    )\n",
    "    params = count_parameters(temp_model)\n",
    "    print(f\"{name:20s}: d={d:4d}, layers={layers}, vocab={vocab:5d} -> {params:>12,} params\")\n",
    "    del temp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 簡単な学習タスク（コピータスク）\n",
    "\n",
    "入力シーケンスをそのまま出力するタスクでTransformerを学習させます。\n",
    "\n",
    "```\n",
    "入力:  [3, 5, 7, 2, 9]\n",
    "出力:  [3, 5, 7, 2, 9]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コピータスク用のデータ生成\n",
    "def generate_copy_data(batch_size, seq_len, vocab_size, pad_idx=0, start_idx=1, end_idx=2):\n",
    "    \"\"\"\n",
    "    コピータスクのデータを生成\n",
    "    \n",
    "    ソース: [random tokens]\n",
    "    ターゲット入力: [<start>, random tokens]\n",
    "    ターゲット出力: [random tokens, <end>]\n",
    "    \"\"\"\n",
    "    # ランダムなトークン（3以降を使用、0=pad, 1=start, 2=end）\n",
    "    tokens = torch.randint(3, vocab_size, (batch_size, seq_len))\n",
    "    \n",
    "    # ソース\n",
    "    src = tokens.clone()\n",
    "    \n",
    "    # ターゲット入力: <start> + tokens\n",
    "    tgt_input = torch.cat([\n",
    "        torch.full((batch_size, 1), start_idx),\n",
    "        tokens\n",
    "    ], dim=1)\n",
    "    \n",
    "    # ターゲット出力（教師信号）: tokens + <end>\n",
    "    tgt_output = torch.cat([\n",
    "        tokens,\n",
    "        torch.full((batch_size, 1), end_idx)\n",
    "    ], dim=1)\n",
    "    \n",
    "    return src, tgt_input, tgt_output\n",
    "\n",
    "# テスト\n",
    "src, tgt_in, tgt_out = generate_copy_data(2, 5, 20)\n",
    "print(\"Source:       \", src[0].tolist())\n",
    "print(\"Target Input: \", tgt_in[0].tolist())\n",
    "print(\"Target Output:\", tgt_out[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コピータスク用の小さなモデル\n",
    "copy_vocab_size = 20\n",
    "copy_model = Transformer(\n",
    "    src_vocab_size=copy_vocab_size,\n",
    "    tgt_vocab_size=copy_vocab_size,\n",
    "    d_model=64,\n",
    "    num_heads=4,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    d_ff=256,\n",
    "    src_pad_idx=0,\n",
    "    tgt_pad_idx=0,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Copy model parameters: {count_parameters(copy_model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習設定\n",
    "optimizer = torch.optim.Adam(copy_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # パディングは無視\n",
    "\n",
    "# 学習ループ\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "seq_len = 8\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "copy_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    # データ生成\n",
    "    src, tgt_in, tgt_out = generate_copy_data(batch_size, seq_len, copy_vocab_size)\n",
    "    src = src.to(device)\n",
    "    tgt_in = tgt_in.to(device)\n",
    "    tgt_out = tgt_out.to(device)\n",
    "    \n",
    "    # 順伝播\n",
    "    logits = copy_model(src, tgt_in)\n",
    "    \n",
    "    # 損失計算\n",
    "    loss = criterion(\n",
    "        logits.reshape(-1, copy_vocab_size),\n",
    "        tgt_out.reshape(-1)\n",
    "    )\n",
    "    \n",
    "    # 精度計算\n",
    "    predictions = logits.argmax(dim=-1)\n",
    "    correct = (predictions == tgt_out).float().mean().item()\n",
    "    \n",
    "    # 逆伝播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(correct)\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}: Loss = {loss.item():.4f}, Accuracy = {correct:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線の可視化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(losses)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(accuracies)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.set_ylim(0, 1.05)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習後のテスト\n",
    "copy_model.eval()\n",
    "\n",
    "# テストデータ\n",
    "test_src, test_tgt_in, test_tgt_out = generate_copy_data(5, seq_len, copy_vocab_size)\n",
    "test_src = test_src.to(device)\n",
    "\n",
    "print(\"Copy Task Test Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated = copy_model.greedy_decode(\n",
    "        test_src,\n",
    "        max_len=seq_len + 2,\n",
    "        start_token_id=1,\n",
    "        end_token_id=2,\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    src_tokens = test_src[i].tolist()\n",
    "    gen_tokens = generated[i].tolist()\n",
    "    # <start>と<end>を除去して比較\n",
    "    gen_clean = [t for t in gen_tokens[1:] if t != 2][:seq_len]\n",
    "    \n",
    "    match = \"✓\" if src_tokens == gen_clean else \"✗\"\n",
    "    print(f\"{match} Input:  {src_tokens}\")\n",
    "    print(f\"  Output: {gen_clean}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "### 学習したこと\n",
    "\n",
    "1. **Transformerの構造**\n",
    "   - Encoder: Self-Attention → FFN を N層\n",
    "   - Decoder: Masked Self-Attention → Cross-Attention → FFN を N層\n",
    "   - Cross-Attentionでソースとターゲットを接続\n",
    "\n",
    "2. **順伝播の流れ**\n",
    "   - ソース → Encoder → Encoder出力\n",
    "   - ターゲット + Encoder出力 → Decoder → 語彙上の確率分布\n",
    "\n",
    "3. **シーケンス生成**\n",
    "   - Greedy: 常に最大確率のトークンを選択\n",
    "   - サンプリング: 確率分布からランダムに選択\n",
    "   - Temperature: 確率分布の鋭さを調整\n",
    "   - Top-K/Top-P: 候補を絞ってからサンプリング\n",
    "\n",
    "4. **パラメータ配分**\n",
    "   - Embedding層: 語彙サイズ × d_model\n",
    "   - Encoder/Decoder: 層数に比例\n",
    "   - Decoderの方がCross-Attention分多い\n",
    "\n",
    "### 次のステップ\n",
    "- 実際の翻訳タスクでの学習\n",
    "- Beam Search の実装\n",
    "- 事前学習モデル（BERT, GPT）との比較"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}