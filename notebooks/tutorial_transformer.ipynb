{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer チュートリアル\n",
    "\n",
    "このノートブックでは、自作Transformerの使い方を解説します。\n",
    "\n",
    "## 目次\n",
    "\n",
    "1. [環境セットアップ](#1-環境セットアップ)\n",
    "2. [アーキテクチャ概要](#2-アーキテクチャ概要)\n",
    "3. [モデルの作成](#3-モデルの作成)\n",
    "4. [パラメータの理解](#4-パラメータの理解)\n",
    "5. [データの準備](#5-データの準備)\n",
    "6. [学習方法](#6-学習方法)\n",
    "7. [推論（生成）方法](#7-推論生成方法)\n",
    "8. [実践例：コピータスク](#8-実践例コピータスク)\n",
    "9. [実践例：加算タスク](#9-実践例加算タスク)\n",
    "10. [Tips & トラブルシューティング](#10-tips--トラブルシューティング)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 環境セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 日本語フォントの設定（macOS）\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = 'Hiragino Sans'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# デバイスの設定\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 自作Transformerのインポート\nfrom src.transformer import Transformer, count_parameters\nfrom src.attention import SelfAttention, MultiHeadAttention\nfrom src.encoder import TransformerEncoder\nfrom src.decoder import TransformerDecoder\nfrom src.position_encoding import PositionalEncoding\nfrom src.feed_forward import FeedForward\n\nprint(\"All modules imported successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2. アーキテクチャ概要\n\nTransformerは以下のコンポーネントで構成されています：\n\n```\nTransformer\n├── Encoder\n│   ├── Token Embedding\n│   ├── Positional Encoding\n│   └── EncoderLayer × N\n│       ├── Multi-Head Self-Attention\n│       ├── Add & Norm\n│       ├── Feed Forward Network\n│       └── Add & Norm\n│\n├── Decoder\n│   ├── Token Embedding\n│   ├── Positional Encoding\n│   └── DecoderLayer × N\n│       ├── Masked Multi-Head Self-Attention\n│       ├── Add & Norm\n│       ├── Multi-Head Cross-Attention\n│       ├── Add & Norm\n│       ├── Feed Forward Network\n│       └── Add & Norm\n│\n└── Output Layer (Linear)\n```\n\n### ファイル構成\n\n| ファイル | 内容 |\n|---------|------|\n| `src/attention.py` | SelfAttention, MultiHeadAttention |\n| `src/position_encoding.py` | PositionalEncoding |\n| `src/feed_forward.py` | FeedForward |\n| `src/encoder.py` | EncoderLayer, Encoder, TransformerEncoder |\n| `src/decoder.py` | DecoderLayer, Decoder, TransformerDecoder |\n| `src/transformer.py` | Transformer（完全なモデル） |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. モデルの作成\n",
    "\n",
    "### 3.1 基本的な使い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最もシンプルなモデル作成\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,  # ソース語彙サイズ\n",
    "    tgt_vocab_size=100,  # ターゲット語彙サイズ\n",
    ")\n",
    "\n",
    "print(f\"Model created!\")\n",
    "print(f\"Parameters: {count_parameters(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# カスタムパラメータでモデル作成\nmodel = Transformer(\n    src_vocab_size=100,       # ソース語彙サイズ\n    tgt_vocab_size=100,       # ターゲット語彙サイズ\n    d_model=128,              # 埋め込み次元\n    num_heads=4,              # Attentionヘッド数\n    num_encoder_layers=3,     # Encoder層数\n    num_decoder_layers=3,     # Decoder層数\n    d_ff=512,                 # FFN中間層の次元\n    max_len=512,              # 最大シーケンス長\n    dropout=0.1,              # ドロップアウト率\n)\n\nprint(f\"Parameters: {count_parameters(model):,}\")\n\n# GPUに移動\nmodel = model.to(device)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 モデル構造の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構造を表示\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# パラメータ数の内訳\ndef count_params_by_module(model):\n    \"\"\"モジュールごとのパラメータ数を表示\"\"\"\n    total = 0\n    for name, param in model.named_parameters():\n        if param.requires_grad:\n            num = param.numel()\n            total += num\n            print(f\"{name}: {num:,}\")\n    print(f\"\\nTotal: {total:,}\")\n\n# 簡易版：主要コンポーネントごと\n# 注意: Transformerの構造は src_embedding, tgt_embedding, encoder, decoder, output_projection\nembedding_params = sum(p.numel() for p in model.src_embedding.parameters()) + \\\n                   sum(p.numel() for p in model.tgt_embedding.parameters())\nencoder_params = sum(p.numel() for p in model.encoder.parameters())\ndecoder_params = sum(p.numel() for p in model.decoder.parameters())\noutput_params = sum(p.numel() for p in model.output_projection.parameters())\n\nprint(\"パラメータ配分:\")\nprint(f\"  Embedding: {embedding_params:,} ({embedding_params/count_parameters(model)*100:.1f}%)\")\nprint(f\"  Encoder:   {encoder_params:,} ({encoder_params/count_parameters(model)*100:.1f}%)\")\nprint(f\"  Decoder:   {decoder_params:,} ({decoder_params/count_parameters(model)*100:.1f}%)\")\nprint(f\"  Output:    {output_params:,} ({output_params/count_parameters(model)*100:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 4. パラメータの理解\n\n### 4.1 主要パラメータ\n\n| パラメータ | 説明 | 推奨値 |\n|-----------|------|--------|\n| `src_vocab_size` | 入力の語彙サイズ | タスク依存 |\n| `tgt_vocab_size` | 出力の語彙サイズ | タスク依存 |\n| `d_model` | 埋め込み次元 | 64, 128, 256, 512 |\n| `num_heads` | Attentionヘッド数 | d_modelの約数 |\n| `num_encoder_layers` | Encoder層数 | 2-6 |\n| `num_decoder_layers` | Decoder層数 | 2-6 |\n| `d_ff` | FFN中間層次元 | d_model × 4 |\n| `max_len` | 最大シーケンス長 | 512, 1024, 5000 |\n| `dropout` | ドロップアウト率 | 0.1 |\n\n### 4.2 パラメータ選択のガイドライン"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# タスク規模別の推奨設定\n",
    "\n",
    "# 小規模タスク（コピー、簡単な変換）\n",
    "small_config = {\n",
    "    'd_model': 64,\n",
    "    'num_heads': 4,\n",
    "    'num_encoder_layers': 2,\n",
    "    'num_decoder_layers': 2,\n",
    "    'd_ff': 256,\n",
    "}\n",
    "\n",
    "# 中規模タスク（算術、パターン認識）\n",
    "medium_config = {\n",
    "    'd_model': 128,\n",
    "    'num_heads': 4,\n",
    "    'num_encoder_layers': 3,\n",
    "    'num_decoder_layers': 3,\n",
    "    'd_ff': 512,\n",
    "}\n",
    "\n",
    "# 大規模タスク（複雑な変換）\n",
    "large_config = {\n",
    "    'd_model': 256,\n",
    "    'num_heads': 8,\n",
    "    'num_encoder_layers': 4,\n",
    "    'num_decoder_layers': 4,\n",
    "    'd_ff': 1024,\n",
    "}\n",
    "\n",
    "# パラメータ数を比較\n",
    "for name, config in [('Small', small_config), ('Medium', medium_config), ('Large', large_config)]:\n",
    "    m = Transformer(src_vocab_size=100, tgt_vocab_size=100, **config)\n",
    "    print(f\"{name}: {count_parameters(m):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 重要な制約\n",
    "\n",
    "```python\n",
    "# d_model は num_heads で割り切れる必要がある\n",
    "assert d_model % num_heads == 0\n",
    "\n",
    "# 例: d_model=128, num_heads=4 → d_k = 128/4 = 32 (OK)\n",
    "# 例: d_model=128, num_heads=5 → エラー！\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. データの準備\n",
    "\n",
    "### 5.1 特殊トークン\n",
    "\n",
    "Transformerでは以下の特殊トークンが必要です：\n",
    "\n",
    "| トークン | 説明 | 用途 |\n",
    "|---------|------|------|\n",
    "| `PAD` | パディング | バッチ内のシーケンス長を揃える |\n",
    "| `START` | 開始トークン | Decoderの最初の入力 |\n",
    "| `END` | 終了トークン | 生成の終了を示す |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特殊トークンの定義\n",
    "PAD_IDX = 0   # パディング\n",
    "START_IDX = 1 # 開始トークン\n",
    "END_IDX = 2   # 終了トークン\n",
    "\n",
    "# 実際のトークンは3から始まる\n",
    "# 例: 数字0-9を使う場合\n",
    "DIGIT_OFFSET = 3  # 数字0 → トークン3, 数字9 → トークン12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 入力データの形式\n",
    "\n",
    "```python\n",
    "# 入力の形式\n",
    "src     = [batch_size, src_seq_len]     # ソースシーケンス\n",
    "tgt_in  = [batch_size, tgt_seq_len]     # ターゲット入力（STARTで始まる）\n",
    "tgt_out = [batch_size, tgt_seq_len]     # ターゲット出力（ENDで終わる）\n",
    "\n",
    "# 例: \"12+34=46\" をコピーするタスク\n",
    "src     = [1, 2, 3, 4]           # 入力: [1, 2, 3, 4]\n",
    "tgt_in  = [START, 1, 2, 3, 4]    # Decoder入力\n",
    "tgt_out = [1, 2, 3, 4, END]      # 正解ラベル\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data(batch_size=4, seq_len=5):\n",
    "    \"\"\"\n",
    "    サンプルデータを作成する例\n",
    "    \n",
    "    Returns:\n",
    "        src: [batch_size, seq_len] - ソースシーケンス\n",
    "        tgt_in: [batch_size, seq_len+1] - Decoder入力（STARTで始まる）\n",
    "        tgt_out: [batch_size, seq_len+1] - 正解ラベル（ENDで終わる）\n",
    "    \"\"\"\n",
    "    # ランダムなソースシーケンス（3-12の範囲、数字0-9に相当）\n",
    "    src = torch.randint(DIGIT_OFFSET, DIGIT_OFFSET + 10, (batch_size, seq_len))\n",
    "    \n",
    "    # ターゲット入力: [START, src...]\n",
    "    tgt_in = torch.cat([\n",
    "        torch.full((batch_size, 1), START_IDX),\n",
    "        src\n",
    "    ], dim=1)\n",
    "    \n",
    "    # ターゲット出力: [src..., END]\n",
    "    tgt_out = torch.cat([\n",
    "        src,\n",
    "        torch.full((batch_size, 1), END_IDX)\n",
    "    ], dim=1)\n",
    "    \n",
    "    return src, tgt_in, tgt_out\n",
    "\n",
    "# テスト\n",
    "src, tgt_in, tgt_out = create_sample_data(batch_size=2, seq_len=4)\n",
    "print(\"Source:     \", src[0].tolist())\n",
    "print(\"Target In:  \", tgt_in[0].tolist())\n",
    "print(\"Target Out: \", tgt_out[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 パディングの処理\n",
    "\n",
    "バッチ内でシーケンス長が異なる場合、パディングが必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, pad_value=PAD_IDX):\n",
    "    \"\"\"\n",
    "    可変長シーケンスをパディング\n",
    "    \n",
    "    Args:\n",
    "        sequences: リスト of リスト（各シーケンス）\n",
    "        pad_value: パディングに使う値\n",
    "    \n",
    "    Returns:\n",
    "        padded: [batch_size, max_len] のテンソル\n",
    "    \"\"\"\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    padded = torch.full((len(sequences), max_len), pad_value, dtype=torch.long)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        padded[i, :len(seq)] = torch.tensor(seq)\n",
    "    \n",
    "    return padded\n",
    "\n",
    "# テスト\n",
    "sequences = [\n",
    "    [3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12],\n",
    "]\n",
    "padded = pad_sequences(sequences)\n",
    "print(\"Padded sequences:\")\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 学習方法\n",
    "\n",
    "### 6.1 基本的な学習ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, src, tgt_in, tgt_out, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    1ステップの学習\n",
    "    \n",
    "    Args:\n",
    "        model: Transformerモデル\n",
    "        src: ソースシーケンス [batch, src_len]\n",
    "        tgt_in: ターゲット入力 [batch, tgt_len]\n",
    "        tgt_out: 正解ラベル [batch, tgt_len]\n",
    "        optimizer: オプティマイザ\n",
    "        criterion: 損失関数\n",
    "    \n",
    "    Returns:\n",
    "        loss: 損失値\n",
    "        accuracy: 精度\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # 順伝播\n",
    "    logits = model(src, tgt_in)  # [batch, tgt_len, vocab_size]\n",
    "    \n",
    "    # 損失計算\n",
    "    loss = criterion(\n",
    "        logits.reshape(-1, logits.size(-1)),  # [batch*tgt_len, vocab_size]\n",
    "        tgt_out.reshape(-1)                    # [batch*tgt_len]\n",
    "    )\n",
    "    \n",
    "    # 精度計算（PADを除く）\n",
    "    predictions = logits.argmax(dim=-1)\n",
    "    mask = tgt_out != PAD_IDX\n",
    "    accuracy = ((predictions == tgt_out) & mask).sum().float() / mask.sum().float()\n",
    "    \n",
    "    # 逆伝播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_generator, num_epochs=100, lr=0.001, verbose=True):\n",
    "    \"\"\"\n",
    "    モデルを学習する\n",
    "    \n",
    "    Args:\n",
    "        model: Transformerモデル\n",
    "        data_generator: データ生成関数 (batch_size) -> (src, tgt_in, tgt_out)\n",
    "        num_epochs: エポック数\n",
    "        lr: 学習率\n",
    "        verbose: 進捗表示\n",
    "    \n",
    "    Returns:\n",
    "        losses: 損失の履歴\n",
    "        accuracies: 精度の履歴\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    iterator = range(num_epochs)\n",
    "    if verbose:\n",
    "        iterator = tqdm(iterator, desc=\"Training\")\n",
    "    \n",
    "    for epoch in iterator:\n",
    "        # データ生成\n",
    "        src, tgt_in, tgt_out = data_generator(batch_size=64)\n",
    "        src = src.to(device)\n",
    "        tgt_in = tgt_in.to(device)\n",
    "        tgt_out = tgt_out.to(device)\n",
    "        \n",
    "        # 学習ステップ\n",
    "        loss, acc = train_step(model, src, tgt_in, tgt_out, optimizer, criterion)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        if verbose:\n",
    "            iterator.set_postfix(loss=f\"{loss:.4f}\", acc=f\"{acc:.4f}\")\n",
    "    \n",
    "    return losses, accuracies\n",
    "\n",
    "\n",
    "def plot_training(losses, accuracies, title=\"Training\"):\n",
    "    \"\"\"学習曲線を描画\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(losses)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title(f'{title} - Loss')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.plot(accuracies)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title(f'{title} - Accuracy')\n",
    "    ax2.set_ylim(0, 1.05)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 学習のポイント\n",
    "\n",
    "1. **学習率**: 0.0001 ~ 0.001 が一般的\n",
    "2. **エポック数**: タスクの複雑さに依存（1000~10000）\n",
    "3. **バッチサイズ**: 32~128\n",
    "4. **勾配クリッピング**: 大きな勾配を制限する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配クリッピングの例\n",
    "def train_step_with_clip(model, src, tgt_in, tgt_out, optimizer, criterion, max_norm=1.0):\n",
    "    \"\"\"勾配クリッピング付きの学習ステップ\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    logits = model(src, tgt_in)\n",
    "    loss = criterion(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        tgt_out.reshape(-1)\n",
    "    )\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # 勾配クリッピング\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 推論（生成）方法\n",
    "\n",
    "学習済みモデルを使って、新しい入力から出力を生成します。\n",
    "\n",
    "### 7.1 Greedy Decode（貪欲法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_example(model, src, max_len=10):\n",
    "    \"\"\"\n",
    "    Greedy Decodeの例\n",
    "    \n",
    "    各ステップで最も確率の高いトークンを選択します。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # モデルの組み込みメソッドを使用\n",
    "        generated = model.greedy_decode(\n",
    "            src,\n",
    "            max_len=max_len,\n",
    "            start_token_id=START_IDX,\n",
    "            end_token_id=END_IDX\n",
    "        )\n",
    "    \n",
    "    return generated\n",
    "\n",
    "# 使い方\n",
    "print(\"Greedy Decode:\")\n",
    "print(\"  最も確率の高いトークンを毎回選択\")\n",
    "print(\"  決定的な出力（同じ入力→同じ出力）\")\n",
    "print(\"  高速\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 サンプリング生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_decode_example(model, src, max_len=10, temperature=1.0, top_k=None, top_p=None):\n",
    "    \"\"\"\n",
    "    サンプリング生成の例\n",
    "    \n",
    "    確率分布からサンプリングして次のトークンを決定します。\n",
    "    \n",
    "    Args:\n",
    "        temperature: 温度パラメータ\n",
    "            - < 1.0: よりシャープ（確定的）\n",
    "            - = 1.0: オリジナルの分布\n",
    "            - > 1.0: よりフラット（ランダム）\n",
    "        top_k: 上位k個のトークンからのみサンプリング\n",
    "        top_p: 累積確率がp以下のトークンからサンプリング（Nucleus Sampling）\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated = model.generate(\n",
    "            src,\n",
    "            max_len=max_len,\n",
    "            start_token_id=START_IDX,\n",
    "            end_token_id=END_IDX,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p\n",
    "        )\n",
    "    \n",
    "    return generated\n",
    "\n",
    "# パラメータの説明\n",
    "print(\"サンプリングパラメータ:\")\n",
    "print()\n",
    "print(\"Temperature:\")\n",
    "print(\"  0.5 - より確定的（同じ出力が多い）\")\n",
    "print(\"  1.0 - オリジナル分布\")\n",
    "print(\"  2.0 - より多様（ランダム）\")\n",
    "print()\n",
    "print(\"Top-K:\")\n",
    "print(\"  k=1  - Greedy Decode と同じ\")\n",
    "print(\"  k=10 - 上位10トークンからサンプリング\")\n",
    "print()\n",
    "print(\"Top-P (Nucleus):\")\n",
    "print(\"  p=0.9 - 累積確率90%までのトークンからサンプリング\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 実践例：コピータスク\n",
    "\n",
    "入力をそのまま出力するタスクで、モデルの基本動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コピータスク用のデータ生成\n",
    "def generate_copy_data(batch_size, seq_len=5):\n",
    "    \"\"\"\n",
    "    コピータスクのデータ生成\n",
    "    入力: [3, 5, 7, 4, 6]\n",
    "    出力: [3, 5, 7, 4, 6]\n",
    "    \"\"\"\n",
    "    # ランダムなシーケンス（3-12）\n",
    "    src = torch.randint(3, 13, (batch_size, seq_len))\n",
    "    \n",
    "    # ターゲット入力: [START, src...]\n",
    "    tgt_in = torch.cat([\n",
    "        torch.full((batch_size, 1), START_IDX),\n",
    "        src\n",
    "    ], dim=1)\n",
    "    \n",
    "    # ターゲット出力: [src..., END]\n",
    "    tgt_out = torch.cat([\n",
    "        src,\n",
    "        torch.full((batch_size, 1), END_IDX)\n",
    "    ], dim=1)\n",
    "    \n",
    "    return src, tgt_in, tgt_out\n",
    "\n",
    "# テスト\n",
    "src, tgt_in, tgt_out = generate_copy_data(2)\n",
    "print(\"Copy Task Example:\")\n",
    "print(f\"  Input:  {src[0].tolist()}\")\n",
    "print(f\"  Output: {[t for t in tgt_out[0].tolist() if t != END_IDX]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル作成\n",
    "copy_model = Transformer(\n",
    "    src_vocab_size=15,\n",
    "    tgt_vocab_size=15,\n",
    "    d_model=64,\n",
    "    num_heads=4,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    d_ff=256,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Parameters: {count_parameters(copy_model):,}\")\n",
    "\n",
    "# 学習\n",
    "losses, accs = train_model(\n",
    "    copy_model, \n",
    "    generate_copy_data, \n",
    "    num_epochs=500, \n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "plot_training(losses, accs, \"Copy Task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト\n",
    "print(\"\\nCopy Task Test Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "copy_model.eval()\n",
    "src, _, _ = generate_copy_data(5)\n",
    "src_device = src.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated = copy_model.greedy_decode(\n",
    "        src_device, \n",
    "        max_len=7,\n",
    "        start_token_id=START_IDX, \n",
    "        end_token_id=END_IDX\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    input_seq = src[i].tolist()\n",
    "    output_seq = [t for t in generated[i].tolist() if t not in [START_IDX, END_IDX, PAD_IDX]]\n",
    "    match = input_seq == output_seq\n",
    "    mark = \"✓\" if match else \"✗\"\n",
    "    print(f\"{mark} Input: {input_seq} -> Output: {output_seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. 実践例：加算タスク\n",
    "\n",
    "2桁の加算（例: 23 + 45 = 68）を学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加算タスク用の定数\n",
    "ADD_PAD = 0\n",
    "ADD_START = 1\n",
    "ADD_END = 2\n",
    "ADD_PLUS = 3\n",
    "ADD_DIGIT_OFFSET = 4  # 数字0 → トークン4\n",
    "\n",
    "def num_to_tokens(n, num_digits):\n",
    "    \"\"\"数字をトークン列に変換\"\"\"\n",
    "    digits = [int(d) + ADD_DIGIT_OFFSET for d in str(n).zfill(num_digits)]\n",
    "    return digits\n",
    "\n",
    "def tokens_to_num(tokens):\n",
    "    \"\"\"トークン列を数字に変換\"\"\"\n",
    "    digits = [t - ADD_DIGIT_OFFSET for t in tokens if ADD_DIGIT_OFFSET <= t <= ADD_DIGIT_OFFSET + 9]\n",
    "    if not digits:\n",
    "        return 0\n",
    "    return int(''.join(map(str, digits)))\n",
    "\n",
    "def generate_addition_data(batch_size, num_digits=2):\n",
    "    \"\"\"\n",
    "    加算タスクのデータ生成\n",
    "    例: 23 + 45 = 68\n",
    "    入力: [2, 3, +, 4, 5]\n",
    "    出力: [6, 8]\n",
    "    \"\"\"\n",
    "    src_list = []\n",
    "    tgt_in_list = []\n",
    "    tgt_out_list = []\n",
    "    \n",
    "    max_num = 10 ** num_digits - 1\n",
    "    result_digits = num_digits + 1  # 桁上がり用\n",
    "    \n",
    "    for _ in range(batch_size):\n",
    "        a = torch.randint(0, max_num + 1, (1,)).item()\n",
    "        b = torch.randint(0, max_num + 1, (1,)).item()\n",
    "        result = a + b\n",
    "        \n",
    "        # ソース: a + b\n",
    "        src_tokens = num_to_tokens(a, num_digits) + [ADD_PLUS] + num_to_tokens(b, num_digits)\n",
    "        \n",
    "        # ターゲット: result\n",
    "        result_tokens = num_to_tokens(result, result_digits)\n",
    "        \n",
    "        src_list.append(torch.tensor(src_tokens))\n",
    "        tgt_in_list.append(torch.tensor([ADD_START] + result_tokens))\n",
    "        tgt_out_list.append(torch.tensor(result_tokens + [ADD_END]))\n",
    "    \n",
    "    src = torch.stack(src_list)\n",
    "    tgt_in = torch.stack(tgt_in_list)\n",
    "    tgt_out = torch.stack(tgt_out_list)\n",
    "    \n",
    "    return src, tgt_in, tgt_out\n",
    "\n",
    "# テスト\n",
    "src, tgt_in, tgt_out = generate_addition_data(3)\n",
    "print(\"Addition Task Examples:\")\n",
    "for i in range(3):\n",
    "    src_t = src[i].tolist()\n",
    "    plus_pos = src_t.index(ADD_PLUS)\n",
    "    a = tokens_to_num(src_t[:plus_pos])\n",
    "    b = tokens_to_num(src_t[plus_pos+1:])\n",
    "    result = tokens_to_num([t for t in tgt_out[i].tolist() if t != ADD_END])\n",
    "    print(f\"  {a} + {b} = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加算モデル作成\n",
    "add_model = Transformer(\n",
    "    src_vocab_size=14,  # PAD, START, END, +, 0-9\n",
    "    tgt_vocab_size=14,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    d_ff=512,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Parameters: {count_parameters(add_model):,}\")\n",
    "\n",
    "# 学習（2桁の加算）\n",
    "def gen_add_2digit(batch_size):\n",
    "    return generate_addition_data(batch_size, num_digits=2)\n",
    "\n",
    "# 注意: 加算タスクは学習に時間がかかります\n",
    "# 完全な精度には10000エポック必要\n",
    "add_losses, add_accs = train_model(\n",
    "    add_model, \n",
    "    gen_add_2digit, \n",
    "    num_epochs=3000,  # 短めのデモ\n",
    "    lr=0.0005\n",
    ")\n",
    "\n",
    "plot_training(add_losses, add_accs, \"Addition Task (2 digits)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト\n",
    "print(\"\\nAddition Task Test Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "add_model.eval()\n",
    "correct = 0\n",
    "total = 20\n",
    "\n",
    "for _ in range(total):\n",
    "    src, _, _ = generate_addition_data(1, num_digits=2)\n",
    "    src_device = src.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated = add_model.greedy_decode(\n",
    "            src_device,\n",
    "            max_len=5,\n",
    "            start_token_id=ADD_START,\n",
    "            end_token_id=ADD_END\n",
    "        )\n",
    "    \n",
    "    src_t = src[0].tolist()\n",
    "    plus_pos = src_t.index(ADD_PLUS)\n",
    "    a = tokens_to_num(src_t[:plus_pos])\n",
    "    b = tokens_to_num(src_t[plus_pos+1:])\n",
    "    expected = a + b\n",
    "    \n",
    "    gen_tokens = [t for t in generated[0].tolist() if t not in [ADD_START, ADD_END, ADD_PAD]]\n",
    "    predicted = tokens_to_num(gen_tokens)\n",
    "    \n",
    "    match = expected == predicted\n",
    "    if match:\n",
    "        correct += 1\n",
    "    mark = \"✓\" if match else \"✗\"\n",
    "    print(f\"{mark} {a:2d} + {b:2d} = {predicted:3d}  (expected: {expected})\")\n",
    "\n",
    "print(f\"\\nAccuracy: {correct}/{total} = {correct/total:.1%}\")\n",
    "print(\"\\n注: 100%精度には10000エポックの学習が必要です\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Tips & トラブルシューティング\n",
    "\n",
    "### 10.1 よくある問題と解決策\n",
    "\n",
    "| 問題 | 原因 | 解決策 |\n",
    "|------|------|--------|\n",
    "| 損失が下がらない | 学習率が高すぎる/低すぎる | 学習率を調整（0.0001~0.001） |\n",
    "| 精度が上がらない | エポック不足 | より多くのエポックで学習 |\n",
    "| 過学習 | モデルが大きすぎる | dropout増加、モデル縮小 |\n",
    "| メモリ不足 | バッチサイズ/モデルが大きい | バッチサイズ縮小、d_model縮小 |\n",
    "| 出力が同じトークンの繰り返し | 学習不足 | エポック増加 |\n",
    "\n",
    "### 10.2 デバッグのコツ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 入出力の形状確認\n",
    "def debug_shapes(model, src, tgt_in):\n",
    "    \"\"\"各層の出力形状を確認\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(f\"Input shapes:\")\n",
    "        print(f\"  src: {src.shape}\")\n",
    "        print(f\"  tgt_in: {tgt_in.shape}\")\n",
    "        \n",
    "        # Encoder出力\n",
    "        enc_output = model.encode(src)\n",
    "        print(f\"\\nEncoder output: {enc_output.shape}\")\n",
    "        \n",
    "        # Decoder出力\n",
    "        logits = model(src, tgt_in)\n",
    "        print(f\"Decoder output (logits): {logits.shape}\")\n",
    "\n",
    "# テスト\n",
    "src, tgt_in, _ = generate_copy_data(2, seq_len=4)\n",
    "debug_shapes(copy_model, src.to(device), tgt_in.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 2. Attention重みの可視化\ndef visualize_attention(model, src, tgt_in):\n    \"\"\"Attention重みを可視化（簡易版）\"\"\"\n    model.eval()\n    \n    # フックを使ってAttention重みを取得\n    attention_weights = []\n    \n    def hook_fn(module, input, output):\n        if isinstance(output, tuple) and len(output) == 2:\n            attention_weights.append(output[1].detach().cpu())\n    \n    # 最初のEncoder層のAttentionにフックを登録\n    # 構造: model.encoder.layers[0].self_attention\n    handle = model.encoder.layers[0].self_attention.register_forward_hook(hook_fn)\n    \n    with torch.no_grad():\n        _ = model(src, tgt_in)\n    \n    handle.remove()\n    \n    if attention_weights:\n        # 最初のサンプル、最初のヘッドのAttention重み\n        attn = attention_weights[0][0, 0].numpy()\n        \n        plt.figure(figsize=(6, 5))\n        plt.imshow(attn, cmap='Blues')\n        plt.colorbar()\n        plt.xlabel('Key Position')\n        plt.ylabel('Query Position')\n        plt.title('Encoder Self-Attention (Head 0)')\n        plt.show()\n    else:\n        print(\"Attention weights not captured\")\n\n# テスト\nsrc, tgt_in, _ = generate_copy_data(1, seq_len=5)\nvisualize_attention(copy_model, src.to(device), tgt_in.to(device))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 パフォーマンス改善のヒント\n",
    "\n",
    "1. **学習率スケジューリング**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmupスケジューラの例\n",
    "def get_lr_scheduler(optimizer, warmup_steps=1000, d_model=128):\n",
    "    \"\"\"\n",
    "    Transformer論文のスケジューラ\n",
    "    lr = d_model^(-0.5) * min(step^(-0.5), step * warmup^(-1.5))\n",
    "    \"\"\"\n",
    "    def lr_lambda(step):\n",
    "        step = max(step, 1)\n",
    "        return d_model ** (-0.5) * min(step ** (-0.5), step * warmup_steps ** (-1.5))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# 使用例\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1.0)\n",
    "# scheduler = get_lr_scheduler(optimizer)\n",
    "# \n",
    "# for epoch in range(num_epochs):\n",
    "#     train_step(...)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early Stoppingの実装\"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.should_stop = False\n",
    "    \n",
    "    def __call__(self, loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        elif loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.should_stop\n",
    "\n",
    "# 使用例\n",
    "# early_stopping = EarlyStopping(patience=10)\n",
    "# \n",
    "# for epoch in range(num_epochs):\n",
    "#     loss = train_step(...)\n",
    "#     if early_stopping(loss):\n",
    "#         print(\"Early stopping!\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 モデルの保存と読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# モデルの保存\ndef save_model(model, path):\n    \"\"\"モデルを保存\"\"\"\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'config': {\n            'src_vocab_size': model.src_embedding.num_embeddings,\n            'tgt_vocab_size': model.tgt_embedding.num_embeddings,\n            'd_model': model.d_model,\n            # 他の設定も保存可能\n        }\n    }, path)\n    print(f\"Model saved to {path}\")\n\n# モデルの読み込み\ndef load_model(path, device='cpu'):\n    \"\"\"モデルを読み込み\"\"\"\n    checkpoint = torch.load(path, map_location=device)\n    config = checkpoint['config']\n    \n    model = Transformer(**config)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"Model loaded from {path}\")\n    return model\n\n# 使用例（コメントアウト）\n# save_model(copy_model, 'copy_model.pt')\n# loaded_model = load_model('copy_model.pt', device)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## まとめ\n",
    "\n",
    "### 基本的な使い方フロー\n",
    "\n",
    "```python\n",
    "# 1. モデル作成\n",
    "model = Transformer(\n",
    "    src_vocab_size=vocab_size,\n",
    "    tgt_vocab_size=vocab_size,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    ").to(device)\n",
    "\n",
    "# 2. データ準備\n",
    "src, tgt_in, tgt_out = generate_data(batch_size)\n",
    "\n",
    "# 3. 学習\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logits = model(src, tgt_in)\n",
    "    loss = criterion(logits.reshape(-1, vocab_size), tgt_out.reshape(-1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 4. 推論\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    generated = model.greedy_decode(src, max_len=10, start_token_id=1, end_token_id=2)\n",
    "```\n",
    "\n",
    "### 重要なポイント\n",
    "\n",
    "1. **学習時間は重要**: 複雑なタスクには十分なエポック数が必要\n",
    "2. **シンプルな表現を使う**: 余計な前処理は不要なことが多い\n",
    "3. **条件を揃えて比較する**: 公平な比較のため、パラメータを統一\n",
    "4. **小さく始める**: まずは小さなモデルで動作確認\n",
    "\n",
    "### 関連ノートブック\n",
    "\n",
    "- `01_self_attention_demo.ipynb`: Self-Attentionの詳細\n",
    "- `02_multi_head_attention_demo.ipynb`: Multi-Head Attentionの詳細\n",
    "- `07_transformer_demo.ipynb`: Transformerの構造解説\n",
    "- `08_diverse_tasks_demo.ipynb`: 様々なタスクでの学習例\n",
    "- `09_addition_improvement.ipynb`: 加算タスクの改善実験"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}